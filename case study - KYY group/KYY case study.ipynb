{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abf4f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a748ba",
   "metadata": {},
   "source": [
    "## Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a541b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_list(lst1 , lst2):\n",
    "    cumulative_list = []\n",
    "    for i in range(len(lst1)):\n",
    "        cumulative_list.append(int(lst1[i] + lst2[i]))\n",
    "    return cumulative_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3215f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define product object\n",
    "import pandas as pd\n",
    "\n",
    "class product_object:\n",
    "    def __init__(self, product_id, number_of_classes, initial_last_class_qty=100000):\n",
    "        self.number_of_classes = number_of_classes\n",
    "        self.product_id = product_id\n",
    "        self.current_inventory = [0] * (number_of_classes - 1) + [initial_last_class_qty]\n",
    "        self.class_log = []\n",
    "\n",
    "    def update_storage_inbound(self, update_class_log):\n",
    "        self.current_inventory = add_list(self.current_inventory, update_class_log)\n",
    "\n",
    "    def update_storage_outbound(self, number_of_product_to_take):\n",
    "        class_indexer = 0\n",
    "        retrieve_table = [0] * self.number_of_classes\n",
    "        number_of_product_to_retrieve = number_of_product_to_take\n",
    "\n",
    "        while number_of_product_to_retrieve != 0:\n",
    "            subtract = number_of_product_to_retrieve - self.current_inventory[class_indexer]\n",
    "\n",
    "            if subtract <= 0:\n",
    "                self.current_inventory[class_indexer] -= number_of_product_to_retrieve\n",
    "                retrieve_table[class_indexer] = number_of_product_to_retrieve\n",
    "                number_of_product_to_retrieve = 0\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                number_of_product_to_retrieve -= self.current_inventory[class_indexer]\n",
    "                retrieve_table[class_indexer] = self.current_inventory[class_indexer]\n",
    "                self.current_inventory[class_indexer] = 0\n",
    "                class_indexer += 1\n",
    "\n",
    "        return retrieve_table\n",
    "\n",
    "    def tenor_update(self, tenor_id, update_class_log):\n",
    "        self.class_log.append([tenor_id, update_class_log])\n",
    "\n",
    "    def print_all_class_logs(self):\n",
    "        class_column = [f\"Class {col_index}\" for col_index in range(1, self.number_of_classes)]\n",
    "        class_column.append('Class backup')\n",
    "        df = pd.DataFrame([log[1] for log in self.class_log], columns=class_column)\n",
    "        df['tenor_index'] = [T[0] for T in self.class_log]\n",
    "        return df\n",
    "\n",
    "    def print_class_name(self):\n",
    "        print(self.product_id)\n",
    "\n",
    "    def print_current_inventory(self):\n",
    "        print(self.current_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "312b5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class object\n",
    "class class_object:\n",
    "    def __init__(self, class_id , n_products , max_capacity = 984 , if_backup = False):\n",
    "        self.class_id = class_id\n",
    "        self.max_capacity = max_capacity\n",
    "        self.current_inventory = np.zeros(n_products)\n",
    "        self.current_capacity = 0\n",
    "        \n",
    "        ### create unlimited backup class\n",
    "        if if_backup:\n",
    "            self.current_inventory = [100000] * n_products\n",
    "            self.max_capacity = 100000\n",
    "            self.current_capacity = sum(self.current_inventory)\n",
    "        \n",
    "\n",
    "\n",
    "    ### Inbound handling \n",
    "    def stuff_product(self, product_index , number_of_product): \n",
    "        spare_room = self.max_capacity - self.current_capacity ### check room left\n",
    "        product_index = int(product_index) ### convert index to int for indexing\n",
    "\n",
    "        if spare_room >= number_of_product: ### if enough room\n",
    "            self.current_inventory[product_index - 1] = self.current_inventory[product_index - 1] + number_of_product\n",
    "            self.current_capacity = sum(self.current_inventory) ### update capacity\n",
    "            return 0\n",
    "\n",
    "        else: ### if not enough room\n",
    "            self.current_inventory[product_index - 1] = self.current_inventory[product_index - 1] + spare_room ### stuff to max\n",
    "            self.current_capacity = self.max_capacity ### update capacity\n",
    "            return number_of_product - spare_room ### return number of products that are not stored\n",
    "    \n",
    "    ### Outbound handling\n",
    "    def take_product(self , product_index , retrieval_count):\n",
    "        self.current_inventory[product_index] = self.current_inventory[product_index] - retrieval_count\n",
    "        self.current_capacity = sum(self.current_inventory)\n",
    "        \n",
    "    def return_numbers(self):\n",
    "        print('current inventory :' , self.current_inventory)\n",
    "        print('current capacity :' , self.current_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c76f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_turnover(df , T, topn, moving_avg = False):\n",
    "    \n",
    "    if moving_avg == True:\n",
    "        demand = df[df['type'] == 'OUT']\n",
    "        supply = df[df['type'] == 'IN']\n",
    "\n",
    "        # create a complete day_id for each product\n",
    "        day = []\n",
    "        for i in range(1, 308):\n",
    "            day.append(i)\n",
    "\n",
    "        product = []\n",
    "        for i in range(1, 21):\n",
    "            for j in range(1, 308):\n",
    "                product.append(i)\n",
    "\n",
    "        complete_date = pd.DataFrame({'day_id' : day * 20, 'product_id' : product})\n",
    "        merged_demand = demand.merge(complete_date, on = ['day_id', 'product_id'], how = 'outer')\n",
    "        merged_demand = merged_demand.sort_values(['product_id', 'day_id']).reset_index()\n",
    "        merged_demand = merged_demand[['day_id', 'product_id', 'quantity']]\n",
    "\n",
    "        # calculate the weekday for each data row\n",
    "        merged_demand['weekday'] = merged_demand['day_id'] % 6\n",
    "        merged_demand['week_id'] = (np.ceil(merged_demand['day_id'] / 6)).astype(int)\n",
    "        merged_demand = merged_demand.fillna(0)\n",
    "\n",
    "        # calculate the moving average. To concate the data, we rename the column name of moving average to quantity_new\n",
    "        merged_demand['quantity_new'] = merged_demand.groupby(['product_id', 'weekday'])['quantity'].transform((lambda x: x.rolling(17, 17).mean())).values\n",
    "        merged_demand['quantity_new'] = merged_demand.groupby(['product_id', 'weekday'])['quantity_new'].shift(1)\n",
    "        merged_demand = merged_demand.fillna(0)\n",
    "        merged_demand['type'] = 'OUT'\n",
    "        merged_demand = merged_demand[['day_id', 'week_id', 'product_id', 'quantity', 'type', 'quantity_new']]\n",
    "        # merged_demand.head(20)\n",
    "\n",
    "        # final dataset\n",
    "        merged_df = pd.concat([supply, merged_demand])\n",
    "        merged_df = merged_df.sort_values(['product_id', 'day_id']).reset_index()\n",
    "        merged_df = merged_df.drop('index', axis = 1)\n",
    "    \n",
    "        df = merged_df\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # add minus sign if the type is OUT\n",
    "    df['quantity_new'] = np.where(df['type'] == 'IN', df['quantity'], df['quantity'] * -1)\n",
    "\n",
    "    # calculate the net quantity\n",
    "    calculate_net_quantity = df.groupby(['product_id', 'day_id', 'type'])['quantity_new'].sum()\n",
    "    calculate_net_quantity = calculate_net_quantity.reset_index().sort_values(['day_id', 'product_id', 'type'])\n",
    "    calculate_net_quantity['grand total'] = abs(calculate_net_quantity['quantity_new'])\n",
    "    \n",
    "    # calculate the turnover rate\n",
    "    daily_turnover_rate = calculate_net_quantity[['day_id', 'product_id', 'grand total', 'quantity_new']]\n",
    "    daily_turnover_rate = daily_turnover_rate.groupby(['product_id', 'day_id'])[['quantity_new', 'grand total']].sum()\n",
    "    daily_turnover_rate['cummulative'] = daily_turnover_rate.groupby(['product_id'])['quantity_new'].cumsum()\n",
    "    daily_turnover_rate = daily_turnover_rate.reset_index()\n",
    "    \n",
    "    # avoid turnover rate from being negative values\n",
    "    daily_turnover_rate['turnover'] = daily_turnover_rate['grand total'] / (daily_turnover_rate['cummulative'] - daily_turnover_rate['cummulative'].min())\n",
    "    \n",
    "    # calculate the frequency based on T\n",
    "    daily_turnover_rate['frequency'] = (np.ceil(daily_turnover_rate['day_id'] / T)).astype(int)\n",
    "    daily_turnover_rate['week_id'] = (np.ceil(daily_turnover_rate['day_id'] / 6)).astype(int)\n",
    "    \n",
    "    # sort by frequency\n",
    "    turnover_rate_series = daily_turnover_rate.groupby(['product_id', 'frequency'])['turnover'].sum() / T\n",
    "    turnover_rate_df = turnover_rate_series.reset_index()\n",
    "    result = daily_turnover_rate.merge(turnover_rate_df, on = ['product_id', 'frequency'])\n",
    "\n",
    "    # select necessary columns\n",
    "    result['IN'] = (result['grand total'] + result['quantity_new']) / 2\n",
    "    result['OUT'] = (result['grand total'] - result['quantity_new']) / 2\n",
    "    result = result[['product_id', 'frequency', 'day_id', 'IN', 'OUT', 'turnover_y', 'week_id']]\n",
    "    \n",
    "    # return topn product\n",
    "    product_list = result['product_id'].unique()\n",
    "    product_list = product_list[:topn]\n",
    "    result = result[result['product_id'].isin(product_list)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91ca68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the cost\n",
    "def supplychain_optimize(turnover_df , number_of_classes, number_of_products):\n",
    "    \n",
    "    # initiate list\n",
    "    class_object_list = []\n",
    "    for i in range(1 , number_of_classes + 1):\n",
    "        class_object_list.append(class_object(f\"{i}\" , number_of_products))\n",
    "\n",
    "    # add one backup storage\n",
    "    class_object_list.append(class_object(number_of_classes + 1 , number_of_products , if_backup = True))\n",
    "    # adjust for backup class\n",
    "    number_of_classes = number_of_classes + 1\n",
    "\n",
    "\n",
    "    # initiate list of top ten products\n",
    "    product_object_list = []\n",
    "    for i in range(1,11):\n",
    "        product_object_list.append(product_object(f\"{i}\" , number_of_classes))\n",
    "    \n",
    "    inbound_logs = []\n",
    "    outbound_logs = []\n",
    "    # for each tenor data\n",
    "    for tenor in list(turnover_df.groupby('frequency')):\n",
    "        # sort tenor data with day id and turnover\n",
    "        tenor_df = tenor[1].sort_values(['day_id' , 'turnover_y'] , ascending = [True, False])\n",
    "        # tenor storing log\n",
    "        tenor_storing_log_outbound = [[0] * number_of_classes] * number_of_products\n",
    "        tenor_storing_log_inbound = [[0] * number_of_classes] * number_of_products\n",
    "\n",
    "        # for each log\n",
    "        for index , row in tenor_df.iterrows():\n",
    "\n",
    "            # handle inbound\n",
    "            storing_log = [0] * number_of_classes # document all classes product i is stored\n",
    "            number_of_product_to_store = row['IN'] # number of product to be arrived\n",
    "            number_of_product_to_take = row['OUT'] # number of product to be delivered\n",
    "            temp_product_count = number_of_product_to_store\n",
    "            non_stored = number_of_product_to_store\n",
    "            product_id = int(row['product_id']) - 1\n",
    "\n",
    "            for class_index in range(len(class_object_list)): # enumerate through all the classes to store\n",
    "                # try to store product into class\n",
    "                non_stored = class_object_list[class_index].stuff_product(row['product_id'] , non_stored)\n",
    "                class_i_stored = temp_product_count - non_stored\n",
    "                storing_log[class_index] =  class_i_stored  # record log\n",
    "\n",
    "                # if completely stored\n",
    "                if non_stored == 0:\n",
    "                    # calculate row change log\n",
    "                    temp_log = add_list(tenor_storing_log_inbound[product_id] , storing_log)\n",
    "                    # update product log\n",
    "                    tenor_storing_log_inbound[product_id] = temp_log\n",
    "                    # update product object\n",
    "                    product_object_list[product_id].update_storage_inbound(storing_log)\n",
    "                    break\n",
    "\n",
    "                # if not enough storage\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            # handle outbound\n",
    "            if number_of_product_to_take == 0: # if no outbound, go to next row\n",
    "                continue\n",
    "            else:\n",
    "                # table of what to retrieve from which table\n",
    "                retrieve_table = product_object_list[product_id].update_storage_outbound(number_of_product_to_take)\n",
    "                for index in range(len(retrieve_table)):\n",
    "                    class_object_list[index].take_product(product_id , retrieve_table[index])\n",
    "\n",
    "                # update tenor_list\n",
    "                tenor_storing_log_outbound[product_id] = add_list(tenor_storing_log_outbound[product_id] , retrieve_table)\n",
    "\n",
    "        # store all the logs\n",
    "        inbound_logs.append(tenor_storing_log_inbound)\n",
    "        outbound_logs.append(tenor_storing_log_outbound)\n",
    "        \n",
    "    return inbound_logs , outbound_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a8a51",
   "metadata": {},
   "source": [
    "## Apply the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1b49999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the default setting\n",
    "# determine the number of time period\n",
    "T = 6\n",
    "\n",
    "# determine the distance for backup storage\n",
    "backup_distance = 999\n",
    "\n",
    "# determine the number of classes\n",
    "number_of_classes = 4\n",
    "\n",
    "# determine the number of products\n",
    "number_of_products = 10\n",
    "\n",
    "# determine which week to calculate the distance\n",
    "week_number = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e81662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "warehouse = pd.read_csv('warehouse_data.csv')\n",
    "\n",
    "# calculate turnover based on the requirements\n",
    "turnover_df = calculate_turnover(warehouse , T , 10 , moving_avg = True)\n",
    "turnover_df = turnover_df[turnover_df['week_id'].isin([week_number])]\n",
    "\n",
    "# read the travel distance\n",
    "travel_distance = pd.read_excel(f'travel distance{number_of_classes}.xlsx')\n",
    "storage_dist = list(travel_distance['Storage Distance'])\n",
    "retrieval_dist = list(travel_distance['Retrieval Distance'])\n",
    "\n",
    "# determine distance for backup storage\n",
    "backup_dist = [backup_distance]\n",
    "storage_dist = storage_dist + backup_dist\n",
    "retrieval_dist = retrieval_dist + backup_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0adaeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the distribution\n",
    "inbound_logs, outbound_logs = supplychain_optimize(turnover_df , number_of_classes , number_of_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24834326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inbound distance : 567.5085714285713\n",
      "Outbound distance : 17435.17428571429\n"
     ]
    }
   ],
   "source": [
    "# inbound\n",
    "inbound_distance = 0\n",
    "for tenor_log in inbound_logs:\n",
    "    for product_log in tenor_log:\n",
    "        for class_index in range(len(product_log)):\n",
    "            inbound_distance = inbound_distance + product_log[class_index] * storage_dist[class_index]\n",
    "\n",
    "inbound_distance = inbound_distance / 35\n",
    "\n",
    "# outbound\n",
    "outbound_distance = 0\n",
    "for tenor_log in outbound_logs:\n",
    "    for product_log in tenor_log:\n",
    "        for class_index in range(len(product_log)):\n",
    "            outbound_distance = outbound_distance + product_log[class_index] * retrieval_dist[class_index]\n",
    "\n",
    "outbound_distance = outbound_distance / 35\n",
    "\n",
    "print(\"Inbound distance :\" , inbound_distance)\n",
    "print(\"Outbound distance :\", outbound_distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
